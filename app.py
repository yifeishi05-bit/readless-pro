import os
import streamlit as st
import pdfplumber
from transformers import pipeline

# ----------------- é¡µé¢è®¾ç½® -----------------
st.set_page_config(page_title="ğŸ“˜ ReadLess Pro â€“ Book Summarizer", page_icon="ğŸ“˜")

st.title("ğŸ“š ReadLess Pro â€“ AI Book Summarizer")
st.caption("Upload a long PDF (even full books!) and get automatic chapter summaries powered by AI (T5-small model).")

# ----------------- å®‰å…¨ç é€»è¾‘ -----------------
REAL_CODE = os.getenv("ACCESS_CODE") or st.secrets.get("ACCESS_CODE", "")
BUY_LINK = "https://readlesspro.lemonsqueezy.com/buy/d0a09dc2-f156-4b4b-8407-12a87943bbb6"
st.sidebar.title("ğŸ”’ Member Login")
code = st.sidebar.text_input("Enter access code (for paid users)", type="password")

if code != REAL_CODE:
    st.warning("Please enter a valid access code to continue.")
    st.markdown(f"ğŸ’³ [Click here to subscribe ReadLess Pro]({BUY_LINK})")
    st.stop()

# ----------------- æ¨¡å‹åŠ è½½ï¼ˆæ‡’åŠ è½½ï¼‰ -----------------
@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="t5-small", tokenizer="t5-small")

# ----------------- ä¸Šä¼ æ–‡ä»¶ -----------------
uploaded = st.file_uploader("ğŸ“„ Upload a PDF file (book, report, or notes)", type="pdf")

if uploaded:
    st.info("âœ… File uploaded successfully. Extracting text in batches...")
    text = ""
    with pdfplumber.open(uploaded) as pdf:
        total_pages = len(pdf.pages)
        st.write(f"Total pages detected: **{total_pages}**")
        for i, page in enumerate(pdf.pages):
            t = page.extract_text()
            if t:
                text += t + "\n"
            if (i + 1) % 20 == 0:  # æ¯ 20 é¡µåˆ†æ®µå¤„ç†
                st.text(f"Loaded {i+1}/{total_pages} pages...")

    if not text.strip():
        st.error("âŒ No readable text found in PDF. It may be scanned images.")
        st.stop()

    # ----------------- åˆ†æ®µç”Ÿæˆç« èŠ‚æ‘˜è¦ -----------------
    summarizer = load_summarizer()
    chunks = [text[i:i + 3000] for i in range(0, len(text), 3000)]
    st.write(f"ğŸ” Splitting text into {len(chunks)} sections for summarization...")

    progress = st.progress(0)
    chapter_summaries = []

    for i, chunk in enumerate(chunks[:10]):  # é™åˆ¶æœ€å¤š10ç« ï¼ˆé˜²æ­¢è¶…æ—¶ï¼‰
        result = summarizer(chunk, max_length=180, min_length=60, do_sample=False)
        chapter_summary = result[0]["summary_text"]
        chapter_summaries.append(f"### ğŸ“– Chapter {i+1}\n{chapter_summary}")
        progress.progress((i + 1) / min(len(chunks), 10))

    # ----------------- è¾“å‡ºç« èŠ‚æ‘˜è¦ -----------------
    st.success("âœ… Chapter Summaries Generated!")
    for ch in chapter_summaries:
        st.markdown(ch)

    # ----------------- å…¨ä¹¦ç»¼åˆæ‘˜è¦ -----------------
    st.divider()
    st.subheader("ğŸ“™ Final Book Summary")
    combined_text = " ".join([s for s in chapter_summaries])
    final_summary = summarizer(combined_text[:6000], max_length=250, min_length=100, do_sample=False)[0]["summary_text"]
    st.write(final_summary)

    st.caption("ğŸš€ Powered by T5-small summarization â€¢ Lightweight and optimized for long PDFs")
